{"hash":"615214260e19768474ba1c21fb0cc06d97f4ae49","data":{"experience":{"title":"Data Engineer at HealthVerity","subtitle":"","position":"Data Engineer","hours":40,"date":"2020-08-04T00:00:00.000Z","endDate":null,"content":"\r\n- Automated big data normalization pipelines processing 5-10 terabytes of healthcare data per day.\r\n- Built utility libraries and tooling around PySpark and AWS EMR to accelerate normalization debugging and development.\r\n- Improved internal data pipeline library built on top of Airflow to handle a wider range of data cases.\r\n- Improved data normalization testing through schema-based representative data generation.\r\n- Migrated legacy normalization jobs from Redshift. Optimized Spark configurations.\r\n- Led efforts to develop and launch internal wiki for knowledge sharing within the organization\r\n- Assisted security team in performing pentesting of systems. Assisted in various security efforts.\r\n","company":"HealthVerity","fileInfo":{"directory":"work"},"tags":[{"title":"python","path":"/tag/python/"},{"title":"pyspark","path":"/tag/pyspark/"},{"title":"aws-emr","path":"/tag/aws-emr/"},{"title":"aws","path":"/tag/aws/"},{"title":"airflow","path":"/tag/airflow/"},{"title":"spark","path":"/tag/spark/"},{"title":"sql","path":"/tag/sql/"},{"title":"spark-sql","path":"/tag/spark-sql/"},{"title":"etl","path":"/tag/etl/"},{"title":"bash","path":"/tag/bash/"},{"title":"make","path":"/tag/make/"},{"title":"docker","path":"/tag/docker/"},{"title":"docker-compose","path":"/tag/docker-compose/"},{"title":"jenkins","path":"/tag/jenkins/"},{"title":"zeppelin","path":"/tag/zeppelin/"},{"title":"big-data","path":"/tag/big-data/"},{"title":"hive","path":"/tag/hive/"},{"title":"hadoop","path":"/tag/hadoop/"},{"title":"healthcare","path":"/tag/healthcare/"}]}},"context":{}}