(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{172:function(t,e,o){"use strict";e.a={name:"VueRemarkRoot",render:function(t){return t("div",null,this.$slots.default)}}},395:function(t,e,o){"use strict";o.r(e);var n=o(4),i=o(172),a=o(0);function r(t){return(r="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(t){return typeof t}:function(t){return t&&"function"==typeof Symbol&&t.constructor===Symbol&&t!==Symbol.prototype?"symbol":typeof t})(t)}a.default.config.optionMergeStrategies;var s={VueRemarkRoot:i.a},l=function(t){var e=t.options.components=t.options.components||{},o=t.options.computed=t.options.computed||{};Object.keys(s).forEach((function(t){"object"===r(s[t])&&"function"==typeof s[t].render?e[t]=s[t]:o[t]=function(){return s[t]}}))},p=a.default.config.optionMergeStrategies,u="__vueRemarkFrontMatter",c={excerpt:"Automated big data pipelines for healthcare data using Spark",title:"Data Engineer at HealthVerity",position:"Data Engineer",company:"HealthVerity",date:"2020-08-04T00:00:00.000Z",endDate:null,img:"healthverity.jpg",hours:40,tags:["python","pyspark","aws-emr","aws","airflow","spark","sql","spark-sql","etl","bash","make","docker","docker-compose","jenkins","zeppelin","big-data","hive","hadoop","healthcare"]};var d=function(t){t.options[u]&&(t.options[u]=c),a.default.util.defineReactive(t.options,u,c),t.options.computed=p.computed({$frontmatter:function(){return t.options[u]}},t.options.computed)},f=Object(n.a)({},(function(){var t=this.$createElement,e=this._self._c||t;return e("VueRemarkRoot",[e("ul",[e("li",[this._v("Automated big data normalization pipelines processing 5-10 terabytes of healthcare data per day.")]),e("li",[this._v("Built utility libraries and tooling around PySpark and AWS EMR to accelerate normalization debugging and development.")]),e("li",[this._v("Improved internal data pipeline library built on top of Airflow to handle a wider range of data cases.")]),e("li",[this._v("Improved data normalization testing through schema-based representative data generation.")]),e("li",[this._v("Migrated legacy normalization jobs from Redshift. Optimized Spark configurations.")]),e("li",[this._v("Led efforts to develop and launch internal wiki for knowledge sharing within the organization")]),e("li",[this._v("Assisted security team in performing pentesting of systems. Assisted in various security efforts.")])])])}),[],!1,null,null,null);"function"==typeof l&&l(f),"function"==typeof d&&d(f);e.default=f.exports}}]);